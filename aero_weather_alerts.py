# -*- coding: utf-8 -*-
"""Airport_weather_alerts

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/embedded/projects/qwiklabs-gcp-04-6a050d0640a7/locations/us-central1/repositories/d985a052-2503-4a35-8cf6-b5e08c3596d4
"""

# Commented out IPython magic to ensure Python compatibility.
# %%bigquery
# CREATE SCHEMA IF NOT EXISTS aero_alerts_dataset
# OPTIONS(
# location="us",
# default_table_expiration_days=14);

# Commented out IPython magic to ensure Python compatibility.
# %%bigquery
# CREATE OR REPLACE EXTERNAL TABLE `qwiklabs-gcp-04-6a050d0640a7.aero_alerts_dataset.aero_alerts_table`
# OPTIONS (
#   format = 'CSV',
#   uris = ['gs://labs.roitraining.com/data-to-ai-workshop/airports.csv'],
#   skip_leading_rows = 1,
#   allow_jagged_rows = false,
#   allow_quoted_newlines = false,
#   field_delimiter = ',',
#   max_bad_records = 10
# )

import os
import pandas as pd
import requests
import vertexai
from google.cloud import bigquery
from vertexai.generative_models import GenerationConfig, GenerativeModel

# --- 1. Configuration --------------------------------------------------------
# Please update these variables with your Google Cloud project details.
PROJECT_ID = "qwiklabs-gcp-04-6a050d0640a7"  # @param {type:"string"}
LOCATION = "us-central1"  # @param {type:"string"}

# BigQuery settings
BQ_DATASET = "aero_alerts_dataset"
SOURCE_TABLE = "aero_alerts_table"
DESTINATION_TABLE = "airport_table"

# --- 2. Initialization -----------------------------------------------------
# Initialize Vertex AI SDK
vertexai.init(project=PROJECT_ID, location=LOCATION)

# Initialize BigQuery Client
# This will use your default credentials if you are authenticated in the notebook.
bq_client = bigquery.Client(project=PROJECT_ID)

print("Vertex AI SDK and BigQuery Client initialized.")

# --- 3. Helper Functions ---------------------------------------------------

def get_extended_weather_forecast(latitude: float, longitude: float) -> list[dict] | None:
    """
    Retrieves the extended weather forecast from the National Weather Service (NWS) API.

    This function simulates the user's existing function. It takes latitude and
    longitude, finds the corresponding NWS forecast grid, and fetches the
    7-day forecast.

    Args:
        latitude: The latitude of the location.
        longitude: The longitude of the location.

    Returns:
        A list of dictionaries containing forecast data for each period,
        or None if the request fails.
    """
    if pd.isna(latitude) or pd.isna(longitude):
        return None

    try:
        # NWS API requires two steps:
        # 1. Get the forecast grid URL for the given lat/lon
        points_url = f"https://api.weather.gov/points/{latitude:.4f},{longitude:.4f}"
        headers = {"User-Agent": "VertexAIFlightAlerts/1.0 (your-email@example.com)"}
        points_response = requests.get(points_url, headers=headers, timeout=10)
        points_response.raise_for_status()
        forecast_url = points_response.json()["properties"]["forecast"]

        # 2. Get the actual forecast from the grid URL
        forecast_response = requests.get(forecast_url, headers=headers, timeout=10)
        forecast_response.raise_for_status()
        forecast_data = forecast_response.json()["properties"]["periods"]

        # The NWS API returns data in the exact format requested by the user.
        return forecast_data

    except requests.exceptions.RequestException as e:
        print(f"Error fetching weather for ({latitude}, {longitude}): {e}")
        return None


def generate_airport_alert(forecast: dict) -> str:
    """
    Uses Gemini to generate a concise operational alert for an airport.

    Args:
        forecast: A dictionary containing detailed weather forecast for one time period.

    Returns:
        A string containing the Gemini-generated alert.
    """
    if not forecast:
        return "Weather data unavailable."

    # Define the model and generation configuration
    model = GenerativeModel("gemini-2.0-flash")
    config = GenerationConfig(
        temperature=0.2,
        top_p=0.8,
        top_k=40,
        max_output_tokens=100
    )

    # Craft a specific prompt for the model
    prompt = f"""
    As an expert aviation meteorologist, create a concise, one-sentence operational alert for airport staff and pilots based on the following weather data.
    Focus only on conditions that could impact flight operations, such as strong winds, gusts, low visibility, thunderstorms, or significant precipitation.
    Do not repeat the temperature unless it is an extreme value affecting ground operations. Start the alert with a single, relevant keyword (e.g., "Wind," "Visibility," "Weather," "Notice").

    Weather Data:
    - Period: {forecast.get('name', 'N/A')}
    - Wind: {forecast.get('windSpeed', 'N/A')} from the {forecast.get('windDirection', 'N/A')}
    - Forecast: {forecast.get('detailedForecast', 'N/A')}

    Example Alert: Wind: Expect strong northwesterly winds creating potential crosswind conditions for most runways.

    Generate the alert now.
    """

    try:
        response = model.generate_content(prompt, generation_config=config)
        return response.text.strip()
    except Exception as e:
        print(f"Error generating alert with Gemini: {e}")
        return "Alert generation failed."


# --- 4. Main Processing Logic ----------------------------------------------

print("\n--- Starting Airport Alert Generation ---")

# Step 1: Query the source table for large airports
sql_query = f"""
    SELECT *
    FROM `{PROJECT_ID}.{BQ_DATASET}.{SOURCE_TABLE}`
    WHERE type = 'large_airport' AND iso_country = 'US'
"""
print(f"Executing query to fetch large airports from {BQ_DATASET}.{SOURCE_TABLE}...")
try:
    df_airports = bq_client.query(sql_query).to_dataframe()
    print(f"Successfully fetched {len(df_airports)} large airports.")
except Exception as e:
    print(f"FATAL: Could not query BigQuery table. Please check table name and permissions. Error: {e}")
    # Exit the script if we can't get the source data
    exit()


# Step 2: Process each airport to get weather and generate an alert
processed_data = []

for index, airport in df_airports.iterrows():
    ident = airport.get('ident', 'Unknown')
    name = airport.get('name', 'Unknown Airport')
    print(f"\nProcessing {ident} ({name})...")

    # Get weather forecast
    forecast_list = get_extended_weather_forecast(
        airport.get("latitude_deg"),
        airport.get("longitude_deg")
    )

    # Prepare a dictionary to hold the new row data
    new_row = airport.to_dict()

    if forecast_list:
        # Get the first time period
        first_period_forecast = forecast_list[0]
        print(f"  > Weather received for '{first_period_forecast.get('name')}'. Generating alert...")

        # Generate Gemini alert
        gemini_alert = generate_airport_alert(first_period_forecast)
        print(f"  > Gemini Alert: {gemini_alert}")

        # Add new columns to the row dictionary
        new_row["gemini_alert"] = gemini_alert
        new_row["forecast_period_name"] = first_period_forecast.get('name')
        new_row["forecast_startTime"] = pd.to_datetime(first_period_forecast.get('startTime'))
        new_row["forecast_temperature"] = first_period_forecast.get('temperature')
        new_row["forecast_temperatureUnit"] = first_period_forecast.get('temperatureUnit')
        new_row["forecast_windSpeed"] = first_period_forecast.get('windSpeed')
        new_row["forecast_windDirection"] = first_period_forecast.get('windDirection')
        new_row["forecast_short"] = first_period_forecast.get('shortForecast')
        new_row["forecast_detailed"] = first_period_forecast.get('detailedForecast')

    else:
        print("  > Failed to retrieve weather data. Skipping weather enrichment.")
        # Add empty columns to maintain table structure
        new_row["gemini_alert"] = "Weather data unavailable."
        new_row["forecast_period_name"] = None
        new_row["forecast_startTime"] = None
        new_row["forecast_temperature"] = None
        new_row["forecast_temperatureUnit"] = None
        new_row["forecast_windSpeed"] = None
        new_row["forecast_windDirection"] = None
        new_row["forecast_short"] = None
        new_row["forecast_detailed"] = None

    processed_data.append(new_row)

# Step 3: Create a new DataFrame with the processed data
df_alerts = pd.DataFrame(processed_data)

# Ensure data types are correct for BigQuery loading
df_alerts['forecast_startTime'] = pd.to_datetime(df_alerts['forecast_startTime'], utc=True)

# --- 5. Load Results into a New BigQuery Table ------------------------------

if not df_alerts.empty:
    print(f"\n--- Loading {len(df_alerts)} records into BigQuery ---")

    destination_table_id = f"{PROJECT_ID}.{BQ_DATASET}.{DESTINATION_TABLE}"

    # Configure the job to create or overwrite the table
    job_config = bigquery.LoadJobConfig(write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE)
    #load_job = client.load_table_from_dataframe(df_alerts, destination_table_id, job_config=job_config)
    #load_job.result()
    #print(f"Success! Table '{dest_table_id}' has been created/updated with {len(enriched_df)} rows.")


    try:
        # Start the load job
        load_job = bq_client.load_table_from_dataframe(
            df_alerts, destination_table_id, job_config=job_config
        )

        load_job.result()  # Wait for the job to complete.

        print(f"Successfully created or updated table: {destination_table_id}")
        # Display a link to the new table in the BigQuery UI
        print(f"View your new table here: https://console.cloud.google.com/bigquery?project={PROJECT_ID}&p={PROJECT_ID}&d={BQ_DATASET}&t={DESTINATION_TABLE}&page=table")

    except Exception as e:
        print(f"FATAL: Failed to load data into BigQuery. Error: {e}")
else:
    print("\nNo data was processed, so no table was created in BigQuery.")